{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb08688220941b02",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Imports\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f724c2898314d50b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-25T06:56:36.671552500Z",
     "start_time": "2023-10-25T06:56:36.665025200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2479f5d060f9caa7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Import Dataset\n",
    "---\n",
    "**Column Description (Data Source: [Smoking and Drinking Dataset with body signal on Kaggle](https://www.kaggle.com/datasets/sooyoungher/smoking-drinking-dataset/data))**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef7abcc13a93e2c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-25T07:16:58.532735600Z",
     "start_time": "2023-10-25T07:16:58.510507400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def percentage_missing_values(data):\n",
    "    total_cells = np.product(data.shape)\n",
    "\n",
    "    missing_cells = data.isnull().sum().sum()\n",
    "\n",
    "    percentage_missing = (missing_cells / total_cells) * 100\n",
    "    return f\"Percentage of missing values: {percentage_missing:.2f}%\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bfeb1e3f35d16c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-25T07:16:59.893380100Z",
     "start_time": "2023-10-25T07:16:58.852453600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/sd.csv')\n",
    "df_copy = df.copy()\n",
    "df_copy.head()\n",
    "df.to_csv('outpu.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7117fe644664da0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-25T07:17:00.052620200Z",
     "start_time": "2023-10-25T07:16:59.893380100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Percentage of missing values: 0.00%'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage_missing_values(df_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d519c23b80ce6ad",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Create Variable Mappings\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "62c16bd516d66e89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-25T07:17:00.667384700Z",
     "start_time": "2023-10-25T07:17:00.647299Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    960124\n",
       "2.0     31222\n",
       "Name: hear_left, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['hear_left'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "65045f220b47faf7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-25T07:17:02.234359600Z",
     "start_time": "2023-10-25T07:17:02.047912500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_copy['SMK_stat_type_cd'] = df_copy['SMK_stat_type_cd'].map({1: 'N', 2: 'Q', 3: 'S'}) # Smoking state, 1(never) = N , 2(used to smoke but quit) = Q, 3(still smoke) = S\n",
    "df_copy['hear_left'] = df_copy['hear_left'].map({1: 'Normal', 2: 'Abnormal'})\n",
    "df_copy['hear_right'] = df_copy['hear_right'].map({1: 'Normal', 2: 'Abnormal'})\n",
    "df_copy['urine_protein'] = df_copy['urine_protein'].map({1: '-', 2: '+/-', 3: '+1', 4: '+2', 5: '+3', 6: '+4'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ada96391d295c6d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-25T07:17:03.036107200Z",
     "start_time": "2023-10-25T07:17:02.943800500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['sex', 'hear_left', 'hear_right', 'urine_protein', 'SMK_stat_type_cd',\n",
      "       'DRK_YN'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_copy.select_dtypes(include=[object,bool]).columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3aceb90fa0a77b5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Encoding \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ace26354f26f6d54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-25T07:17:05.191814Z",
     "start_time": "2023-10-25T07:17:05.172391400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def one_hot_encode_dataframe(df,columns):\n",
    "    copy = df.copy()\n",
    "    ohe = pd.get_dummies(df_copy, columns=columns)\n",
    "    return ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dccb15878175d72a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-25T07:17:27.292219600Z",
     "start_time": "2023-10-25T07:17:26.946181200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns = ['sex','hear_left','hear_right','urine_protein'] # We can then re-use the one hot encode method depending if we want to predict smoker or drinker\n",
    "ohe_df = one_hot_encode_dataframe(df_copy, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "86b6752fe6caf205",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-25T07:17:27.786037900Z",
     "start_time": "2023-10-25T07:17:27.754327600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>waistline</th>\n",
       "      <th>sight_left</th>\n",
       "      <th>sight_right</th>\n",
       "      <th>SBP</th>\n",
       "      <th>DBP</th>\n",
       "      <th>BLDS</th>\n",
       "      <th>tot_chole</th>\n",
       "      <th>...</th>\n",
       "      <th>hear_left_Abnormal</th>\n",
       "      <th>hear_left_Normal</th>\n",
       "      <th>hear_right_Abnormal</th>\n",
       "      <th>hear_right_Normal</th>\n",
       "      <th>urine_protein_+/-</th>\n",
       "      <th>urine_protein_+1</th>\n",
       "      <th>urine_protein_+2</th>\n",
       "      <th>urine_protein_+3</th>\n",
       "      <th>urine_protein_+4</th>\n",
       "      <th>urine_protein_-</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>170</td>\n",
       "      <td>75</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>180</td>\n",
       "      <td>80</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>130.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>165</td>\n",
       "      <td>75</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>120.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>175</td>\n",
       "      <td>80</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>145.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>165</td>\n",
       "      <td>60</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>138.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  height  weight  waistline  sight_left  sight_right    SBP   DBP  \\\n",
       "0   35     170      75       90.0         1.0          1.0  120.0  80.0   \n",
       "1   30     180      80       89.0         0.9          1.2  130.0  82.0   \n",
       "2   40     165      75       91.0         1.2          1.5  120.0  70.0   \n",
       "3   50     175      80       91.0         1.5          1.2  145.0  87.0   \n",
       "4   50     165      60       80.0         1.0          1.2  138.0  82.0   \n",
       "\n",
       "    BLDS  tot_chole  ...  hear_left_Abnormal  hear_left_Normal  \\\n",
       "0   99.0      193.0  ...                   0                 1   \n",
       "1  106.0      228.0  ...                   0                 1   \n",
       "2   98.0      136.0  ...                   0                 1   \n",
       "3   95.0      201.0  ...                   0                 1   \n",
       "4  101.0      199.0  ...                   0                 1   \n",
       "\n",
       "   hear_right_Abnormal  hear_right_Normal  urine_protein_+/-  \\\n",
       "0                    0                  1                  0   \n",
       "1                    0                  1                  0   \n",
       "2                    0                  1                  0   \n",
       "3                    0                  1                  0   \n",
       "4                    0                  1                  0   \n",
       "\n",
       "   urine_protein_+1  urine_protein_+2  urine_protein_+3 urine_protein_+4  \\\n",
       "0                 0                 0                 0                0   \n",
       "1                 0                 0                 0                0   \n",
       "2                 0                 0                 0                0   \n",
       "3                 0                 0                 0                0   \n",
       "4                 0                 0                 0                0   \n",
       "\n",
       "  urine_protein_-  \n",
       "0               1  \n",
       "1               1  \n",
       "2               1  \n",
       "3               1  \n",
       "4               1  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74b8f0b",
   "metadata": {},
   "source": [
    "### Modeling with One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27aa8ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import statsmodels.api as sm\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, r2_score, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef0ff04",
   "metadata": {},
   "source": [
    "Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067bea91",
   "metadata": {},
   "outputs": [],
   "source": [
    "categ = ohe_df.select_dtypes(include=[\"object\", \"category\"])\n",
    "num = ohe_df.select_dtypes(exclude=[\"object\", \"category\"])\n",
    "\n",
    "\n",
    "prep = make_column_transformer( #utilized chatgpt\n",
    "        (OneHotEncoder(), categ),(\n",
    "        StandardScaler(),num))\n",
    "\n",
    "l  = LinearRegression()\n",
    "pipe = make_pipeline(prep,l)\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa00ca91",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ohe_df.drop('', axis =1)\n",
    "y = ohe_df[''] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "linear_predictions = pipe.predict(X_test) \n",
    "\n",
    "\n",
    "linear_mse = mean_squared_error(y_test, linear_predictions) \n",
    "linear_r2 = r2_score(y_test, linear_predictions) \n",
    "linear_rmse = np.sqrt(linear_mse) \n",
    "linear_meany = np.mean(y)\n",
    "linear_rmsem = linear_rmse/ linear_meany \n",
    "\n",
    "print(\"Linear Regression Model:\")\n",
    "print(\"Mean Squared Error:\", linear_mse)\n",
    "print(\"R-squared:\", linear_r2)\n",
    "print(\"RMSEM:\", linear_rmsem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c089855",
   "metadata": {},
   "source": [
    "KNN Regression \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a2a375",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_regressor = KNeighborsRegressor(n_neighbors=5)  \n",
    "\n",
    "pipeline_knn = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', knn_regressor)\n",
    "])\n",
    "\n",
    "X = ohe_df.drop('', axis=1)\n",
    "y = ohe_df['']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "pipeline_knn.fit(X_train, y_train)\n",
    "\n",
    "knn_predictions = pipeline_knn.predict(X_test)\n",
    "\n",
    "knn_mse = mean_squared_error(y_test, knn_predictions)\n",
    "knn_r2 = r2_score(y_test, knn_predictions)\n",
    "knn_rmse = np.sqrt(knn_mse)\n",
    "knn_meany = np.mean(y)\n",
    "knn_rmsem = knn_rmse / knn_meany\n",
    "\n",
    "print(\"KNN Regression Model:\")\n",
    "print(\"Mean Squared Error:\", knn_mse)\n",
    "print(\"R-squared:\", knn_r2)\n",
    "print(\"RMSEM:\", knn_rmsem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3910c6",
   "metadata": {},
   "source": [
    "Classifiers Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60f03d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classifier_metrics(classifier, X_train, y_train, X_test, y_test): #used chatgpt for the function arguments settings and the intializiatio of them\n",
    "    categ = ohe_df.select_dtypes(include=[\"object\", \"category\"])\n",
    "    num = ohe_df.select_dtypes(exclude=[\"object\", \"category\"])\n",
    "\n",
    "    preprocessor = make_column_transformer(\n",
    "        (OneHotEncoder(), categ),\n",
    "        (StandardScaler(), num)\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', classifier)\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    test_predictions = pipeline.predict(X_test)\n",
    "    train_predictions = pipeline.predict(X_train)\n",
    "\n",
    "    accuracy_test = accuracy_score(y_test, test_predictions)\n",
    "    roc_auc_test = roc_auc_score(y_test, test_predictions)#utilized chatgpt\n",
    "    kappa_test = cohen_kappa_score(y_test, test_predictions)#utilized chatgpt\n",
    "    f1_test = f1_score(y_test, test_predictions)\n",
    "\n",
    "    accuracy_train = accuracy_score(y_train, train_predictions)\n",
    "    roc_auc_train = roc_auc_score(y_train, train_predictions)#utilized chatgpt\n",
    "    kappa_train = cohen_kappa_score(y_train, train_predictions)#utilized chatgpt\n",
    "    f1_train = f1_score(y_train, train_predictions)\n",
    "\n",
    "    return {\n",
    "        'Test Accuracy': accuracy_test,\n",
    "        'Test ROC AUC': roc_auc_test,\n",
    "        'Test Kappa': kappa_test,\n",
    "        'Test F1 Score': f1_test,\n",
    "        'Train Accuracy': accuracy_train,\n",
    "        'Train ROC AUC': roc_auc_train,\n",
    "        'Train Kappa': kappa_train,\n",
    "        'Train F1 Score': f1_train\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56dd6e4",
   "metadata": {},
   "source": [
    "KNN Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9ec8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "y = df2['']\n",
    "X = df2.drop('',axis=1)\n",
    "\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=4)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2, random_state=42)\n",
    "knn_metrics = evaluate_classifier_metrics(knn_classifier, X_train, y_train, X_test, y_test)\n",
    "print(\"KNN Metrics:\")\n",
    "for metric, value in knn_metrics.items(): \n",
    "    print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e22084",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97d6de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_classifier = LogisticRegression()\n",
    "logistic_metrics = evaluate_classifier_metrics(logistic_classifier, X_train, y_train, X_test, y_test)\n",
    "print(\"Logistic Regression Metrics:\")\n",
    "for metric, value in logistic_metrics.items(): #utilized chatgpt to debug the for loop\n",
    "    print(f\"{metric}: {value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
